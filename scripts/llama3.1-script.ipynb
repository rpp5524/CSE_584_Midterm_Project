{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "url = \"https://api.perplexity.ai/chat/completions\"\n",
    "\n",
    "def get_prompt(sentence, word_length):\n",
    "    prompt = f\"\"\"You are an expert sentence completion bot. I will provide you with incomplete sentences. Your job is to complete these sentences in {word_length} words. Also, the output should just be the remaining part of the sentence and not the entire sentence. I am providing you with a few examples of input and expected output. Example 1: \n",
    "    input: The rain was\n",
    "    output: going to flood the entire city\n",
    "    Example 2: \n",
    "    input: The party was about to end after\n",
    "    output: the birthday cake was distributed\n",
    "    Example 3:\n",
    "    input: Jack fought with him because\n",
    "    output: he was insecure and jealous\n",
    "    Now it is your turn, complete this sentence and provide me only the remaining part of the sentence: \"\"\"    \n",
    "\n",
    "    prompt += sentence\n",
    "    \n",
    "    return prompt\n",
    "\n",
    "def main(prompt, temperature, top_p, top_k, max_output_tokens, percentage_ai_content):\n",
    "    payload = {\n",
    "        \"model\": \"llama-3.1-70b-instruct\",\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"Complete this sentence.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt\n",
    "            }\n",
    "        ],\n",
    "        \"temperature\": temperature,\n",
    "        \"top_p\": top_p,\n",
    "        \"return_citations\": True,\n",
    "        \"search_domain_filter\": [\"perplexity.ai\"],\n",
    "        \"return_images\": False,\n",
    "        \"return_related_questions\": False,\n",
    "        \"search_recency_filter\": \"month\",\n",
    "        \"top_k\": top_k,\n",
    "        \"stream\": False,\n",
    "        \"presence_penalty\": 0,\n",
    "        \"frequency_penalty\": 1\n",
    "    }\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer $add_api_key\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "\n",
    "    response = requests.request(\"POST\", url, json=payload, headers=headers)\n",
    "\n",
    "    return response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing word value: 5\n",
      "Incomplete Sentence 0: Thequestionofhowhuman decision-makersdeterminetheb\n",
      "Complete Sentence 0: est course of action arises\n",
      "Incomplete Sentence 1: informed by na turalistic p riors . The agent m ig\n",
      "Complete Sentence 1: hates the new policy changes\n",
      "Incomplete Sentence 2: Classification problems are central to many applications of machine learning, including\n",
      "Complete Sentence 2: natural language processing and computer vision\n",
      "Incomplete Sentence 3: Lifelong learning policies aim to create a skilled workforce capable of adapting to the demands\n",
      "Complete Sentence 3: of a rapidly changing economy\n",
      "Incomplete Sentence 4: Bayesian methods are widely used in machine\n",
      "Complete Sentence 4: learning and artificial intelligence applications\n",
      "Saved CSV for word: 5\n",
      "Processing word value: 10\n",
      "Incomplete Sentence 0: Thequestionofhowhuman decision-makersdeterminetheb\n",
      "Complete Sentence 0: est course of action is still debated\n",
      "Incomplete Sentence 1: informed by na turalistic p riors . The agent m ig\n",
      "Complete Sentence 1: hates the uncertainty and chaos that comes with it\n",
      "Incomplete Sentence 2: Classification problems are central to many applications of machine learning, including\n",
      "Complete Sentence 2: natural language processing and computer vision systems today everywhere\n",
      "Incomplete Sentence 3: Lifelong learning policies aim to create a skilled workforce capable of adapting to the demands\n",
      "Complete Sentence 3: of a rapidly changing global economy and technological advancements\n",
      "Incomplete Sentence 4: Bayesian methods are widely used in machine\n",
      "Complete Sentence 4: learning and artificial intelligence applications\n",
      "Saved CSV for word: 10\n",
      "Processing word value: 15\n",
      "Incomplete Sentence 0: Thequestionofhowhuman decision-makersdeterminetheb\n",
      "Complete Sentence 0: est course of action in complex situations remains largely unanswered\n",
      "Incomplete Sentence 1: informed by na turalistic p riors . The agent m ig\n",
      "Complete Sentence 1: hates the uncertainty and ambiguity of human behavior\n",
      "Incomplete Sentence 2: Classification problems are central to many applications of machine learning, including\n",
      "Complete Sentence 2: natural language processing and computer vision systems\n",
      "Incomplete Sentence 3: Lifelong learning policies aim to create a skilled workforce capable of adapting to the demands\n",
      "Complete Sentence 3: of a rapidly changing global economy and technological advancements\n",
      "Incomplete Sentence 4: Bayesian methods are widely used in machine\n",
      "Complete Sentence 4: learning and artificial intelligence applications today\n",
      "Saved CSV for word: 15\n",
      "Processing word value: 20\n",
      "Incomplete Sentence 0: Thequestionofhowhuman decision-makersdeterminetheb\n",
      "Complete Sentence 0: est course of action in complex situations has puzzled researchers for decades\n",
      "Incomplete Sentence 1: informed by na turalistic p riors . The agent m ig\n",
      "Complete Sentence 1: hts be able to learn from its environment\n",
      "Incomplete Sentence 2: Classification problems are central to many applications of machine learning, including\n",
      "Complete Sentence 2: image and speech recognition, natural language processing, and recommender systems.\n",
      "Incomplete Sentence 3: Lifelong learning policies aim to create a skilled workforce capable of adapting to the demands\n",
      "Complete Sentence 3: of an ever-changing global economy and technological landscape\n",
      "Incomplete Sentence 4: Bayesian methods are widely used in machine\n",
      "Complete Sentence 4: learning and artificial intelligence applications today\n",
      "Saved CSV for word: 20\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import json\n",
    "\n",
    "# Load the original data\n",
    "df = pd.read_csv(f\"../data/test_corpus/test_original.csv\")\n",
    "temperature = 0.2\n",
    "top_p = 0.9\n",
    "top_k = 0\n",
    "max_output_tokens = 8192\n",
    "word_list= [\"5\", \"10\", \"15\", \"20\"]\n",
    "percentage_ai_count = \"1-2 lines\"\n",
    "# temperature_list = [0.2, 0.4, 0.6, 0.8, 1]\n",
    "# List of top_p values to process\n",
    "# top_p_list = [0.8, 0.6, 0.4, 0.2]\n",
    "\n",
    "# Counter to track when to sleep\n",
    "request_count = 0\n",
    "\n",
    "# Iterate over each top_p value\n",
    "for word in word_list:\n",
    "    print(f\"Processing word value: {word}\")\n",
    "    \n",
    "    # Create a copy of the original dataframe to avoid overwriting\n",
    "    df_copy = df.copy()\n",
    "    count = 0\n",
    "    \n",
    "    for index, row in df_copy.iterrows():\n",
    "        prompt = get_prompt(row['Xi'], word)  # Get the prompt from 'Xi'\n",
    "        \n",
    "        # Replace newlines with spaces and remove double quotes\n",
    "        main_res= main(prompt, temperature, top_p, top_k, max_output_tokens, percentage_ai_count)\n",
    "        response_g = json.loads(main_res)\n",
    "        response = response_g[\"choices\"][0][\"message\"][\"content\"].replace('\\n', ' ').replace('\"', '')\n",
    "        print(f\"Incomplete Sentence {count}: {row['Xi']}\")\n",
    "        print(f\"Complete Sentence {count}: {response}\")\n",
    "        count += 1\n",
    "\n",
    "        # Update the dataframe with the results\n",
    "        df_copy.at[index, 'Xj'] = response  # Store the actual response, not the list\n",
    "        df_copy.at[index, 'model'] = 'gemini-1.5-flash'\n",
    "        df_copy.at[index, 'temperature'] = temperature\n",
    "        df_copy.at[index, 'top_p'] = top_p\n",
    "        df_copy.at[index, 'top_k'] = top_k\n",
    "        df_copy.at[index, 'max_output_tokens'] = max_output_tokens\n",
    "        df_copy.at[index, 'percentage_ai_count'] = word\n",
    "\n",
    "        request_count += 1  # Increase the request count\n",
    "\n",
    "    # Save the dataframe to a CSV specific to this top_p value\n",
    "    df_copy.to_csv(f\"../data/test_corpus/llama_3.1/ai_generated_content/num_of_words{word}.csv\", index=False)\n",
    "    print(f\"Saved CSV for word: {word}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incomplete : Thequestionofhowhuman decision-makersdeterminetheb\n",
      "Completed: est course of action in complex situations has puzzled philosophers and scientists for centuries\n",
      "Incomplete : informed by na turalistic p riors . The agent m ig\n",
      "Completed: hts have been influenced by the environment and past experiences\n",
      "Incomplete : Classification problems are central to many applications of machine learning, including\n",
      "Completed: natural language processing, image recognition, and recommender systems.\n",
      "Incomplete : Lifelong learning policies aim to create a skilled workforce capable of adapting to the demands\n",
      "Completed: of a rapidly changing global economy and technological advancements.\n",
      "Incomplete : Bayesian methods are widely used in machine\n",
      "Completed: learning and artificial intelligence to make predictions and classify data.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "incompleted_sentences = []\n",
    "for index, row in df.iterrows():\n",
    "    prompt = get_prompt(row['Xi'])\n",
    "    g = json.loads(perplexity_model(prompt))\n",
    "    incompleted_sent = g[\"choices\"][0][\"message\"][\"content\"]\n",
    "    incompleted_sentences.append(incompleted_sent)\n",
    "\n",
    "    print(f\"Incomplete : {row['Xi']}\")\n",
    "    print(f'Completed: {incompleted_sent}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding column Xj\n",
    "df['Xj'] = incompleted_sentences\n",
    "\n",
    "# Adding column model\n",
    "df['model'] = 'llama-3.1-70b-instruct'\n",
    "\n",
    "df.head()\n",
    "\n",
    "df.to_csv(\"llama_3.1_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Xi'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Xi'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m  \u001b[38;5;66;03m# Skip rows if restarting from a checkpoint\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Get the prompt from the 'Xi' column\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m prompt \u001b[38;5;241m=\u001b[39m get_prompt(\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mXi\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Call the model and get the response (modify according to your LLM function)\u001b[39;00m\n\u001b[1;32m     20\u001b[0m response \u001b[38;5;241m=\u001b[39m perplexity_model(prompt)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/core/series.py:1112\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1109\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[key]\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[0;32m-> 1112\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1114\u001b[0m \u001b[38;5;66;03m# Convert generator to list before going through hashable part\u001b[39;00m\n\u001b[1;32m   1115\u001b[0m \u001b[38;5;66;03m# (We will iterate through the generator there to check for slices)\u001b[39;00m\n\u001b[1;32m   1116\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/core/series.py:1228\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1225\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[label]\n\u001b[1;32m   1227\u001b[0m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[0;32m-> 1228\u001b[0m loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1230\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(loc):\n\u001b[1;32m   1231\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[loc]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Xi'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Load your dataframe (assuming you have already read the CSV)\n",
    "df = pd.read_csv('../data/research_corpus/cleaned_Corpus.csv')\n",
    "\n",
    "# Initialize a list to store the LLM responses for the 'Xj' column\n",
    "incompleted_sentences = []\n",
    "checkpoint_interval = 100  # Save after every 100 rows\n",
    "start_row = 0  # Change if restarting from a certain row\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    if index < start_row:\n",
    "        continue  # Skip rows if restarting from a checkpoint\n",
    "\n",
    "    # Get the prompt from the 'Xi' column\n",
    "    prompt = get_prompt(row['Xi'])\n",
    "\n",
    "    # Call the model and get the response (modify according to your LLM function)\n",
    "    response = perplexity_model(prompt)\n",
    "    g = json.loads(response)\n",
    "    incompleted_sent = g[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "    # Append the LLM response for 'Xj' column\n",
    "    incompleted_sentences.append(incompleted_sent)\n",
    "    print(f\"Record {index+1}\")\n",
    "    print(f\"Incomplete: {row['Xi']}\")\n",
    "    print(f\"Completed: {incompleted_sent}\")\n",
    "\n",
    "    # Add response to 'Xj' column and model name to 'model' column\n",
    "    df.at[index, 'Xj'] = incompleted_sent\n",
    "    df.at[index, 'model'] = 'llama-3.1-70b-instruct'\n",
    "\n",
    "    # Save checkpoint after every 100 rows\n",
    "    if (index + 1) % checkpoint_interval == 0:\n",
    "        df.to_csv(f\"llama_3.1_dataset_checkpoint_{index+1}.csv\", index=False)\n",
    "        print(f\"Checkpoint saved after processing {index+1} rows.\")\n",
    "\n",
    "# Save the final dataframe to CSV\n",
    "df.to_csv(\"llama_3.1_dataset_final.csv\", index=False)\n",
    "print(\"Final dataset saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
